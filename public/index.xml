<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Zach Thornton</title><link>http://www.onebitwonders.com/</link><description>Recent content on Zach Thornton</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Mon, 09 Jul 2018 14:35:49 -0400</lastBuildDate><atom:link href="http://www.onebitwonders.com/index.xml" rel="self" type="application/rss+xml"/><item><title>Jackson Exception in Oozie</title><link>http://www.onebitwonders.com/posts/jackson-exception-in-oozie/</link><pubDate>Mon, 09 Jul 2018 14:35:49 -0400</pubDate><guid>http://www.onebitwonders.com/posts/jackson-exception-in-oozie/</guid><description>Jackson Exception in Oozie When using Spark2 within an oozie workflow, I&amp;rsquo;ve noticed that out of the box Hortonworks provides conflicting jars with Jackson, which leads to an exception when you launch a Spark2 job. The exception usually looks something like this:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 2018-07-06 14:45:53,763 [Thread-43] ERROR org.apache.spark.sql.execution.datasources.FileFormatWriter - Aborting job null. java.</description></item><item><title>Building Oozie Workflows</title><link>http://www.onebitwonders.com/posts/building-oozie-workflows/</link><pubDate>Sat, 30 Jun 2018 14:19:06 -0400</pubDate><guid>http://www.onebitwonders.com/posts/building-oozie-workflows/</guid><description>Building Oozie Workflows Over here at Tufts there&amp;rsquo;s an ongoing effort to convert legacy ETL processes over to our new Hadoop cluster. At the cornerstone of such an effort lies the workflow scheduling tool Oozie. Oozie handles both the generation of DAG based workflows, as well as the scheduling of said workflows through markup described files. Oozie can handle several different types of actions, whether they be executing scripts(bash/pig/hive/spark), running java programs, or performing actions within HDFS.</description></item></channel></rss>